---
title: "[Заметки по R](http://bdemeshev.github.io/r_cycle/): Процедура отбора моделей MCS"
date: "`r format(Sys.time(), '%d.%m.%Y')`"
output: html_document
lang: russian
---

Процедура MCS (model confidence set) позволяет из множества моделей отбросить «плохие». По окончании процедуры отбора могут остаться неотброшенными несколько моделей. 

Процедура выглядит так:

1. Для каждой модели рассчитывается её «степень несовершенства», $v_i$. 

2. Проверяется гипотеза о том, что все модели одинаково «хороши».

3. Если гипотеза не отвергается, то процедура заканчивается. Если не все модели одинаково хороши, то самая плохая модель отбрасывается.

4. Переходим к шагу 1 с меньшим числом моделей.


На шаге 1 в качестве степени несовершенства используется один из двух показателей качества прогнозов. Можно рассчитать отставание модели по качеству прогнозов от самого сильного конкурента. Можно рассчитать усреднённое отставание модели от остальных.

На шаге 2 используют одну из трёх статистик: $T_{max}$, $T_{R}$, $T_{SQ}$. Статистики $T_{max}$ и $T_{R}$ измеряют, насколько плоха самая плохая из моделей. Статистика $T_{SQ}$ показывает, насколько сильно разняться модели по качеству прогнозов. Распределение у всех трёх статистик не стандартное. 

Для более подбробного изложения введём обозначения:

$l_{i,t}$ --- штраф модели $i$ за наблюдение $t$, например, квадратичный
\[
l_{i,t} = (\hat y^{(i)}_t - y_t)^2,
\]
где $\hat y_t^{(i)}$ --- прогноз по $i$-ой модели.

$d_{ij,t} = l_{i,t} - l_{j,t}$ --- отставание модели $i$ от модели $j$ в прогнозе наблюдения $t$. Если $d_{ij,t}>0$, значит модель $i$ прогнозирует момент времени $t$ хуже модели $j$.

$\bar d_{ij} = \sum_t d_{ij,t} / T$ --- отставание модели $i$ от модели $j$ по качеству прогнозов. Если $d_{ij}>0$, значит модель $i$ прогнозирует хуже модели $j$. 

$\bar d_{i.} = \sum_j \bar d_{ij} / m$ --- усреднённое отставание модели $i$ от конкурентов.

$t_{i.}=\frac{\bar d_{i.}}{se(\bar d_{i.})}$, стандартная ошибка рассчитывается с помощью бутстрэпа. Можно интерпретировать как стандартизированное усреднённое отставание модели $i$ от конкурентов.

$t_{ij}=\frac{\bar d_{ij}}{se(\bar d_{ij})}$, стандартная ошибка рассчитывается с помощью бутстрэпа. Можно интерпретировать как стандартизированное отставание модели $i$ от модели модели $j$. Заметим, что $t_{ij}=-t_{ji}$ и $se(t_{ij})=se(t_{ji})$.



Пакет MCS в \verb|R| выводит результаты последней процедуры отбрасывания модели:

-  $\verb|v_M|_i= t_{i.}$.  Усреднённая отставание модели $i$ от конкурентов. Индекс $M$ означает, что на основании $\verb|v_M|_i$ считается статистика $T_{max}$.
- $\verb|v_R|_i=\max_j t_{ij}$.   Отставание модели $i$ от самого сильного её конкурента. Индекс $R$ означает, что на основании $\verb|v_R|_i$ считается статистика $T_{R}$. Отрицательное значение возможно только у модели-лидера.
- $\verb|Loss|_i = \sum_t l_{i,t}/T$ --- среднее значение функции потерь модели $i$
- $\verb|Rank_R|_i$ --- рейтинг модели $i$, рассчитанный с помощью $\verb|v_R|_i$. Чем меньше, тем лучше.
- $\verb|Rank_M|_i$ --- рейтинг модели $i$ если считать с помощью $\verb|v_M|_i$. Чем меньше, тем лучше.



$T_{max} = \max_i t_{i.} = \max_i  \verb|v_i_M|$ (R считает, matlab не считает)

$T_{R} = \max_{ij} t_{ij} = \max_i \verb|v_i_R|$ (R и matlab)

$T_{SQ} = \sum_{i<j} t_{ij}^2$ (R не считает, matlab считает)


Подгружаем пакеты:
```{r}
library("MCS") # процедура отбора моделей MCS
library("parallel") # параллельные вычисления
```


```{r, results = "markup"}
data(Loss) # матрица $l_{i,t}$, в столбцах модели, в строках время
Loss_mini <- Loss[1:100, 20:30]
best_models <- MCSprocedure(Loss_mini, verbose = FALSE)
print(best_models)
```


Проблемы метода:

* Чувствительность к посторонним альтернативам

Например, алгоритм из трёх моделей может оставлять две, а добавишь в набор сравниваемых моделей ещё четыре модели хуже любой исходной, и ни одна не будет откинута!

Численный пример. Генерируем три примерно одинаковые модели:
```{r}
n <- 100

set.seed(23)
true_y <- rep(0, n) + rnorm(n, sd = 0.0005)
m1 <- rep(0.1, n) + rnorm(n, sd = 0.0005)
m2 <- rep(0.10001, n) + rnorm(n, sd = 0.0005)
m3 <- rep(0.1001, n) + rnorm(n, sd = 0.0005)

# MCS with 3 models

forecasts <- cbind(m1, m2, m3)
n_models <- ncol(forecasts)
actual <- matrix(rep(true_y, n_models), ncol = n_models)

loss <- (actual - forecasts) ^ 2 
best_models <- MCSprocedure(loss)
```


Добавляем ещё четыре заведомо более плохих модели:

```{r}
m4 <- rep(0.25, n) + rnorm(n, sd = 0.0005)
m5 <- rep(0.25, n) + rnorm(n, sd = 0.0005)
m6 <- rep(0.25, n) + rnorm(n, sd = 0.0005)
m7 <- rep(0.25, n) + rnorm(n, sd = 0.0005)

# MCS with 7 models

forecasts <- cbind(m1, m2, m3, m4, m5, m6, m7)
n_models <- ncol(forecasts)
actual <- matrix(rep(true_y, n_models), ncol = n_models)

loss <- (actual - forecasts) ^ 2
best_models <- MCSprocedure(loss)
```


* Квадратичная зависимость времени работы от количества моделей

Если увеличить количество моделей в 10 раз, то время работы возрастёт в 100 раз :)

Чтобы уменьшить время работы можно использовать несколько ядер процессора. Сначала узнаем, сколько ядер у доступного нам процессора:
```{r}
detectCores()
```

Обычно оптимальная производительность достигается, если задействовано ядер чуть меньше, чем имеется в наличии. Возьмем 6 ядер для данного опыта!

```{r}
cluster <- makeCluster(6)
best_models <- MCSprocedure(Loss_mini, verbose = FALSE, cl = cluster)
stopCluster(cluster)

print(best_models)
```

В конце надо обязательно остановить кластер :)





Почиташки:

[Hansen, Lunde, Nason - 2011](https://www.kevinsheppard.com/images/3/35/Hansen_Lunde_Nason.pdf) Здесь $T_R$, $T_{max}$

[Hansen, Lunde, Nason - 2003](http://mit.econ.au.dk/vip_htm/alunde/ACADEMIC/RESEARCH/PAPERS/MCSvola.pdf) Здесь $T_{max}$, $T_{SQ}$

[Bernardi, Catania](http://arxiv.org/pdf/1410.8504v1) Виньетка пакета MCS.

